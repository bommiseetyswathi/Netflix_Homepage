{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUcExzgMqZ7Z/E8h0AEPFe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bommisetty-swathi/Netflix_Homepage/blob/main/211FA07113_Experiment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PRACTICE - 2 :**\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "##**Aim** :\n",
        "\n",
        "##**1**. Finding median and mode if the data given in the group of frequencies distribution.\n",
        "\n",
        "##**2**. Findig the range of the data.\n",
        "\n",
        "##**3**.Finding 1st quartile,2nd quartile and 3rd quartile of the data.\n",
        "\n",
        "##**4**.Finding inter quartile range of the data.\n",
        "\n",
        "##**5.**.Find outliers in the given data using IQR\n",
        "\n",
        "##**6**.Represent the ve number summary of the data.\n",
        "\n",
        "##**7**.Matrix representation of data.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VAQ8Uc3vE9tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset\n",
        "ci=[[10,20],[20,30],[30,40],[40,50],[50,60]]\n",
        "f=[10,20,30,40,50]"
      ],
      "metadata": {
        "id": "lZ9qyu8kGEwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Median :**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "###Median represents the middle value of the data set.\n",
        "\n",
        "##**Finding the Median of Grouped Data**:\n",
        "\n",
        "###In a grouped data, it is not possible to find the median for the given observation by looking at the cumulative frequencies. The middle value of the given data will be in some class interval. So, it is necessary to find the value inside the class interval that divides the whole distribution into two halves. In this scenario, we have to find the median class. To find the median class, we have to find the cumulative frequencies of all the classes and n/2. After that, locate the class whose cumulative\n",
        "###frequency is greater than (nearest to) n/2. The class is called the median class.\n",
        "\n",
        "###Where\n",
        "\n",
        "###**l** is the lower limit of the median class\n",
        "\n",
        "###**n** is the number of observations\n",
        "\n",
        "###**f** is the frequency of median class\n",
        "\n",
        "###**h** is the class size\n",
        "\n",
        "###**cf** is the cumulative frequency of class preceding the median class."
      ],
      "metadata": {
        "id": "8ARxLOXpGc6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Frequencies**: 5 , 12 , 20 , 15 , 8.\n",
        "\n",
        "###To find the median, we follow these steps:\n",
        "\n",
        "###**Step 1:**\n",
        "###Find the Cumulative Frequency\n",
        "###Add up the frequencies to get the cumulative frequency for each interval:\n",
        "\n",
        "###**Cf :** 5 , 17 , 37 , 52 , 60.\n",
        "\n",
        "###**Step 2 :** Find the Median Class The median class is the class interval that contains the median\n",
        "###value. It is the interval for which the cumulative frequency is closest to (n/2), where 'n' is the total number of data points.In our example, 'n' is the sum of the frequencies, which is 60. The median class is the interval\n",
        "###where the cumulative frequency is closest to 60/2 = 30. So, the median class is [30-40) with a cumulative frequency of 37.\n",
        "\n",
        "###**Step 3 :** Use the Median Formula to Approximate the Median The median formula for grouped data is given by:\n",
        "\n",
        "###**Median ≈ L + ((n/2) - F) * w / f**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###**where:**\n",
        "\n",
        "###**L** is the lower boundary of the median class ([30-40), which is 30 in this case).\n",
        "\n",
        "### **n** is the total number of data points (sum of frequencies, which is 60).\n",
        "\n",
        "###**F** is the cumulative frequency of the class before the median class (the cumulative frequency of\n",
        "the class [20-30), which is 17).\n",
        "\n",
        "###**w** is the width of the class interval ([40-50) - [30-40) = 10 in this case).\n",
        "\n",
        "###**f** is the frequency of the median class (the frequency of the class [30-40), which is 20).\n",
        "\n",
        "###Now, plug in the values:\n",
        "\n",
        "###Median ≈ 30 + ((60/2) - 17) * 10 / 20\n",
        "\n",
        "###Median ≈ 30 + (30 - 17) * 10 / 20\n",
        "\n",
        "###Median ≈ 30 + 13 * 0.5\n",
        "\n",
        "###Median ≈ 30 + 6.5\n",
        "\n",
        "###Median ≈ 36.5\n",
        "\n",
        "###So, the approximate median of the grouped data is 36.5 years.\n"
      ],
      "metadata": {
        "id": "XlwBY3kcIka8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the following variables defined: ci, f\n",
        "\n",
        "si = len(f)\n",
        "cf = [sum(f[:i+1]) for i in range(si)]\n",
        "sum_cf = sum(f)\n",
        "sum_half = sum_cf / 2\n",
        "\n",
        "index = next(i for i, x in enumerate(cf) if x >= sum_half)\n",
        "\n",
        "l, F, fr = ci[index][0], cf[index-1], f[index]\n",
        "c = ci[0][1] - ci[0][0]\n",
        "median = l + (((sum_half - F) / fr) * c)\n",
        "\n",
        "print(\"Median:\", median)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhsLg8yWfQD3",
        "outputId": "f710aaf0-a925-4a37-e6c3-b67b6226f8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median: 43.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Mode:**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###The mode is a statistical measure used in data analysis to find the value that appears most frequently in a dataset. In other words, it is the data point that has the highest frequency.Unlike the median and mean, the mode can be used with both numerical and categorical data.\n",
        "\n",
        "##**Finding mode of a grouped data:**\n",
        "\n",
        "###To find the mode of a grouped data set, we need to identify the class interval with the highest frequency, i.e., the interval that occurs most frequently. Let's go through an example to find the mode of a grouped data set.\n",
        "\n",
        "##**Example:**\n",
        "\n",
        "##Suppose we have the following grouped data representing the test scores of students:\n",
        "\n",
        "##**Score Range:**\n",
        "\n",
        "##(50-60),(60-70),(70-80),(80-90),(90,100).\n",
        "\n",
        "##**Frequency:**\n",
        "\n",
        "##8,12,20,15,5.\n",
        "\n",
        "##To find the mode, we follow these steps:\n",
        "\n",
        "##**Step 1:** Identify the Class Interval with the Highest Frequency From the given data, we can see that the class interval [70-80) has the highest frequency of 20. So, the mode class is [70-80).\n",
        "\n",
        "##**Step 2 :** Calculate the Mode The mode is the value that represents the highest peak in the data distribution. In grouped data, we can approximate the mode using the following formula:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> **Mode ≈ L + ((Fm - F1) / (Fm - F0))*w**\n",
        "\n",
        "###where:\n",
        "\n",
        "###**L** is the lower boundary of the mode class ([70-80), which is 70 in this case).\n",
        "\n",
        "###**Fm** is the frequency of the mode class (the frequency of the class [70-80), which is 20)\n",
        "\n",
        "###**F1**is the frequency of the class before the mode class (the frequency of the class [60-70), which is 12).\n",
        "\n",
        "###**F0** is the frequency of the class after the mode class (the frequency of the class [80-90), which is 15).\n",
        "\n",
        "###**w** is the width of the class interval ([80-90) - [70-80) = 10 in this case).\n",
        "\n",
        "###Now, plug in the values:\n",
        "\n",
        "###Mode ≈ 70 + ((20 - 12) / (20 - 15)) * 10\n",
        "\n",
        "###Mode ≈ 70 + (8 / 5) * 10\n",
        "\n",
        "###Mode ≈ 70 + 16\n",
        "\n",
        "###Mode ≈ 86\n",
        "\n",
        "###So, the approximate mode of the grouped data is 86, which means that the mode class is [70-80) and the mode score is 86.\n"
      ],
      "metadata": {
        "id": "6iG5qWIgLjTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.(ii)Finding mode if the data given in the group of frequencies distribution.\n",
        "for x in f:\n",
        "      if x > max:\n",
        "        max = x\n",
        "maxval=max\n",
        "si=len(f)\n",
        "for i in range(si):\n",
        "  if maxval==f[i]:\n",
        "    index=i\n",
        "l=ci[index][0]\n",
        "h=ci[0][1]-ci[0][0]\n",
        "f1=f[index]\n",
        "f0=f[index-1]\n",
        "f2=f[index+1]\n",
        "mode=l+(((f1-f0)/(2*f1-f0-f2))*h)\n",
        "print(\"Mode:\",mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "v4VqKISsv-k3",
        "outputId": "cb504ae6-f46c-445c-e09b-29c035747a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ae19f65b86ee>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#1.(ii)Finding mode if the data given in the group of frequencies distribution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'int' and 'builtin_function_or_method'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Range:**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###In statistics, the range is a simple measure that represents the difference between the largest and smallest values in a dataset. It provides an indication of the spread or variability of the data. The range is one of the simplest measures of dispersion and is easy to calculate.\n",
        "\n",
        "##**To find the range of a dataset, follow these steps:**\n",
        "\n",
        "##**Step - 1 :** Arrange the data in ascending or descending order.\n",
        "\n",
        "##**Step - 2 :** Subtract the smallest value from the largest value.Mathematically, the range (R) of a dataset is given by:\n",
        "\n",
        "###**Range (R) = Largest Value - Smallest Value**\n",
        "\n",
        "\n",
        "##The range is heavily influenced by outliers since it only considers the two extreme values in the dataset. Therefore, it may not be the most robust measure of dispersion for datasets with extreme values or significant variability\n",
        "\n",
        "##Let's look at an example to calculate the range of a dataset:\n",
        "\n",
        "##**Example:**\n",
        "\n",
        "##Consider the following dataset of exam scores:\n",
        "\n",
        "##72, 85, 90, 78, 65, 92, 80, 88, 70, 95\n",
        "\n",
        "##**Step 1:** Arrange the data in ascending order:\n",
        "##65, 70, 72, 78, 80, 85, 88, 90, 92, 95\n",
        "\n",
        "##**Step 2:** Calculate the range:\n",
        "\n",
        "##Range = Largest Value - Smallest Value\n",
        "\n",
        "##Range = 95 - 65\n",
        "\n",
        "##Range = 30\n",
        "\n",
        "##So, the range of the given dataset is 30. This means the scores in the dataset range from 65 to 95, and there is a spread of 30 points between the lowest and highest scores."
      ],
      "metadata": {
        "id": "rRjOTZhyNp4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Range\n",
        "f=[10,20,30,40,50]\n",
        "maxval=max(f)\n",
        "minval=min(f)\n",
        "range=(maxval-minval)\n",
        "print(\"Range:\",range)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydC4RPM5vppg",
        "outputId": "b907a85a-dd30-4e9e-9788-35a5906696e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Range: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Quartile :**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "###In statistics, quartiles are values that divide a dataset into four equal parts. The three quartiles, denoted as Q1, Q2 (the median), and Q3, are used to understand the distribution and spread of the data. The median (Q2) is the value that separates the lower 50% of the data from the upper 50%. Q1 divides the lower 25% of the data from the upper 75%, and Q3 divides the lower 75% from the upper 25%.\n",
        "\n",
        "\n",
        "###To find the quartiles, the data should be arranged in ascending order, and the position of each quartile can be calculated using the following formulas:\n",
        "\n",
        "\n",
        "##**Q1 (First Quartile): (n + 1) / 4**\n",
        "\n",
        "\n",
        "\n",
        "##**Q2 (Second Quartile or Median): (n + 1) / 2**\n",
        "\n",
        "\n",
        "##**Q3 (Third Quartile): 3 * (n + 1) / 4**\n",
        "\n",
        "\n",
        "##where 'n' is the number of data points in the dataset.\n",
        "\n",
        "##Let's go through an example to find the quartiles:\n",
        "\n",
        "##**Example :**\n",
        "##Consider the following dataset of exam scores:\n",
        "\n",
        "##82, 76, 90, 68, 88, 94, 78, 85, 80, 72\n",
        "\n",
        "##**Step 1:** Arrange the data in ascending order:\n",
        "##68, 72, 76, 78, 80, 82, 85, 88, 90, 94\n",
        "\n",
        "##**Step 2:** Calculate the quartiles:\n",
        "\n",
        "##Q1 (First Quartile):\n",
        "\n",
        "##Q1 position = (10 + 1) / 4 = 11 / 4 = 2.75\n",
        "\n",
        "##Since the position is not an integer, we take the average of the 2nd and 3rd values:\n",
        "\n",
        "##**Q1 = (76 + 78) / 2 = 77**\n",
        "\n",
        "##Q2 (Second Quartile or Median):\n",
        "\n",
        "##Q2 position = (10 + 1) / 2 = 11 / 2 = 5.5 Again, since the position is not an integer, we take the average of the 5th and 6th values:\n",
        "\n",
        "##**Q2 = (80 + 82) / 2 = 81**\n",
        "\n",
        "##Q3 (Third Quartile):\n",
        "\n",
        "##Q3 position = 3 * (10 + 1) / 4 = 33 / 4 = 8.25\n",
        "\n",
        "##Again, since the position is not an integer, we take the average of the 8th and 9th values:\n",
        "\n",
        "##**Q3 = (88 + 90) / 2 = 89**\n",
        "\n",
        "##So, the quartiles for the given dataset are:\n",
        "\n",
        "##**Q1 = 77**\n",
        "\n",
        "##**Q2 = 81 (Median)**\n",
        "\n",
        "##**Q3 = 89**\n",
        "\n",
        "##These quartiles divide the dataset into four equal parts and provide valuable insights into the distribution and central tendency of the data.\n"
      ],
      "metadata": {
        "id": "SWpjcdBOPAn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first quartile\n",
        "f1=sorted(f)\n",
        "si=len(f1)\n",
        "q1=(int)((25/100)*si)\n",
        "print(\"First Quartile:\",f1[q1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgNut9ogxCRd",
        "outputId": "ddf51985-af67-4ab2-af19-d7b51da56d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Quartile: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#second quartile\n",
        "f1=sorted(f)\n",
        "si=len(f1)\n",
        "q2=(int)((50/100)*si)\n",
        "print(\"Second Quartile:\",f1[q2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jj_WIzTxvVM",
        "outputId": "aa386bff-27b2-46f7-c046-30547c9c3de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second Quartile: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#third quartile\n",
        "f1=sorted(f)\n",
        "si=len(f1)\n",
        "q3=(int)((75/100)*si)\n",
        "print(\"Third Quartile:\",f1[q3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNDrnKmcx2qy",
        "outputId": "14bed452-fdbd-4d35-f4b7-145d1e102a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Third Quartile: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**The interquartile range (IQR) :**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###The interquartile range (IQR) is a measure of statistical dispersionthat represents the range between the first quartile (Q1) and the third quartile (Q3) of a dataset. It gives us an idea of the spread of the middle 50% of the data and is a robust measure as it is less affected by outliers compared to the range. Mathematically, to find the interquartile range (IQR) of a dataset:\n",
        "\n",
        "   \n",
        "\n",
        "### ➡ Arrange the data in ascending order\n",
        "### ➡ Calculate Q1 (the first quartile) and Q3 (the third quartile) using the formulas:\n",
        "\n",
        "###**Q1 position = (n + 1) / 4**\n",
        "\n",
        "###**Q3 position = 3 * (n + 1) / 4**\n",
        "\n",
        "###**IQR = Q3 - Q1**\n",
        "\n",
        "###The IQR represents the spread of the middle 50% of the data, and it contains the values between Q1 and Q3, which corresponds to the second quartile (median) of the dataset.\n",
        "\n",
        "###Let's use an example to find the interquartile range (IQR):\n",
        "\n",
        "###**Example:** Consider the following dataset of exam scores:\n",
        "\n",
        "###82, 76, 90, 68, 88, 94, 78, 85, 80, 72\n",
        "\n",
        "###**Step 1:** Arrange the data in ascending order:\n",
        "\n",
        "###68, 72, 76, 78, 80, 82, 85, 88, 90, 94\n",
        "\n",
        "###**Step 2:** Calculate Q1 and Q3:\n",
        "\n",
        "###Q1 position = (10 + 1) / 4 = 11 / 4 = 2.75\n",
        "\n",
        "###Q3 position = 3 * (10 + 1) / 4 = 33 / 4 = 8.25\n",
        "\n",
        "###Taking the average of the 2nd and 3rd values, we get:\n",
        "\n",
        "###Q1 = (76 + 78) / 2 = 77\n",
        "\n",
        "###Q3 = (88 + 90) / 2 = 89\n",
        "\n",
        "###**Step 3:** Calculate the interquartile range (IQR):\n",
        "\n",
        "###IQR = Q3 - Q1 = 89 - 77 = 12\n",
        "\n",
        "###So, the interquartile range (IQR) for the given dataset is 12. This means that the middle 50% of the data is spread over a range of 12 units.\n"
      ],
      "metadata": {
        "id": "LJva9HTdSVyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#interquartile range\n",
        "f1=sorted(f)\n",
        "q1=(int((25/100)*si))+1\n",
        "q3=(int((75/100)*si))+1\n",
        "IQR=(f1[q3]-f1[q1])\n",
        "print(\"Inter quartile range:\",IQR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va3t-Fu-x6n5",
        "outputId": "77c0e8b0-09eb-4fc2-b96a-5b8468456e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inter quartile range: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**The five-number summary :**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "###The five-number summary is a descriptive statistical summary of adataset that consists of five key values: the minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum. These values provide important insights into the distribution and spread of the data.\n",
        "\n",
        "###To represent the five-number summary of a dataset, follow these steps:\n",
        "\n",
        "\n",
        "###➡ Arrange the **data** in ascending order.\n",
        "\n",
        "###➡ Calculate the minimum and maximum values, which are the smallest and largest values in the dataset, respectively.\n",
        "\n",
        "###➡ Calculate Q1 (the first quartile) and Q3 (the third quartile) using the formulas:\n",
        "\n",
        "\n",
        "###**Q1 position = (n + 1) / 4**\n",
        "\n",
        "###**Q3 position = 3 * (n + 1) / 4**\n",
        "\n",
        "where 'n' is the number of data points in the dataset.\n",
        "\n",
        "*   Q1 is the value at the Q1 position, and Q3 is the value at the Q3 position.\n",
        "*   Calculate the median (Q2), which is the value at the middle position in the dataset.\n",
        "*   Calculate the median (Q2), which is the value at the middle position in the dataset.\n",
        "\n",
        "\n",
        "##**Minimum, Q1, Median, Q3, Maximum**\n",
        "\n",
        "###Let's use the same example dataset of exam scores from the previous responses to find the fivenumber summary:\n",
        "\n",
        "###**Example :** Consider the following dataset of exam scores:\n",
        "\n",
        "###82, 76, 90, 68, 88, 94, 78, 85, 80, 72\n",
        "\n",
        "###**Step 1:** Arrange the data in ascending order:\n",
        "\n",
        "###68, 72, 76, 78, 80, 82, 85, 88, 90, 94\n",
        "\n",
        "###**Step 2:** Calculate the minimum and maximum:\n",
        "\n",
        "###**Minimum: 68**\n",
        "\n",
        "###**Maximum: 94**\n",
        "\n",
        "###**Step 3:** Calculate Q1 and Q3:\n",
        "\n",
        "###**Q1 position = (10 + 1) / 4 = 11 / 4 = 2.75**\n",
        "\n",
        "###**Q3 position = 3 * (10 + 1) / 4 = 33 / 4 = 8.25**\n",
        "\n",
        "###Taking the average of the 2nd and 3rd values, we get:\n",
        "\n",
        "###**Q1 = (76 + 78) / 2 = 77**\n",
        "\n",
        "###**Q3 = (88 + 90) / 2 = 89**\n",
        "\n",
        "###**Step 4:** Calculate the median (Q2):\n",
        "\n",
        "###**Median (Q2) = (80 + 82) / 2 = 81**\n",
        "\n",
        "###The five-number summary for the given dataset is:\n",
        "\n",
        "###**Minimum : 68**\n",
        "\n",
        "###**Q1: 77**\n",
        "\n",
        "###**Median (Q2): 81**\n",
        "\n",
        "###**Q3: 89**\n",
        "\n",
        "###**Maximum: 94**\n",
        "\n",
        "###These five values provide a concise representation of the dataset's central tendency and spread, which is helpful for data analysis and comparison"
      ],
      "metadata": {
        "id": "GEAXPvudUcNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Outliers:**\n",
        "\n",
        "Turkey's method is a mathematical method to find outliers. As per the Turkey method, the outliers are the points lying beyond the upper boundary of **Q3 +1.5 IQR** and the lower boundary of **Q1 - 1.5 IQR.**"
      ],
      "metadata": {
        "id": "SynnBz69SCZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5 number summary\n",
        "f=[10,30,35,45,40,50,55,65,60,80,75,85,100]\n",
        "m1=min(f)\n",
        "si=len(f)\n",
        "q1=(int((25/100)*si))+1\n",
        "f.sort()\n",
        "m2=f[q1]\n",
        "q2=(int((50/100)*si))+1\n",
        "m3=f[q2]\n",
        "q3=(int((75/100)*si))+1\n",
        "m4=f[q3]\n",
        "m5=max(f)\n",
        "print(\"5 Number summary values are\",m1,m2,m3,m4,m5)\n",
        "#outliers\n",
        "IQR=(m4-m2)\n",
        "print(\"lower bound\")\n",
        "lb=q1-(1.5*IQR)\n",
        "print(lb)\n",
        "ub=q3+(1.5*IQR)\n",
        "print(\"upper bound\")\n",
        "print(ub)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0jUgMZ8x8x6",
        "outputId": "08f45a74-9947-4b3f-c4d0-a7557d748228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 Number summary values are 10 45 60 80 100\n",
            "lower bound\n",
            "-48.5\n",
            "upper bound\n",
            "62.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Converting a dictionary to a DataFrame:**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "###Converting a dictionary to a DataFrame is a fundamental operation in data manipulation using the pandas library in Python. A DataFrame is a two-dimensional data structure that allows you to store and organize data in a tabular format, similar to a spreadsheet or SQL table. Each column in the DataFrame represents an attribute, and each row represents an individual data point or observation.\n",
        "\n",
        "###When converting a dictionary to a DataFrame, the keys of the dictionary are used as column names, and the corresponding values become the data for each column. The values in the dictionary can be in the form of lists, arrays, or other iterable structures. The process of converting a dictionary to a DataFrame can be summarized in the followingsteps:\n",
        "\n",
        "###**Prepare the dictionary:**\n",
        "\n",
        "###Create a dictionary where each key represents a column name, and thecorresponding value is a collection of data points for that column.\n",
        "\n",
        "###**Import pandas library:**\n",
        "\n",
        "###Import the pandas library, which provides the DataFrame constructor to\n",
        "###create and manipulate DataFrames\n",
        "\n",
        "###**Use DataFrame constructor:**\n",
        "\n",
        "###Utilize the pd.DataFrame() constructor, passing the dictionary as an argument, to create the DataFrame. The keys of the dictionary will be treated as column names, and the values will become the data for each column.  \n",
        "\n",
        "###**Display or further manipulate the DataFrame:**\n",
        "\n",
        "###Once the DataFrame is created, you can display it, perform data analysis, apply various operations, and conduct data mining tasks using pandas' built-in functions and methods. DataFrames are versatile data structures that enable efficient data manipulation, filtering,aggregation, and visualization, making them widely used in data analysis and data science tasks. By converting a dictionary to a DataFrame, you can leverage the rich functionality ofpandas to explore, analyze, and gain insights from your data in a structured and organizedmanner.\n",
        "\n",
        "###**Converting a DataFrame to a dissimilarity matrix:**\n",
        "\n",
        "###Converting a DataFrame to a dissimilarity matrix is a common operation in data analysis and data mining, especially in clustering and similarity-based tasks. A dissimilarity matrix, also known as a distance matrix, represents the dissimilarities or distances between data points in a dataset. The process of converting a DataFrame to a dissimilarity matrix can be summarized in the following steps:\n",
        "\n",
        "###**Preprocess the DataFrame:**\n",
        "\n",
        "###Ensure that the DataFrame contains the relevant data for computing dissimilarities. Depending on the task, this may involve handling missing values, scaling or normalizing the data,  and selecting the appropriate attributes for comparison.\n",
        "\n",
        "###**Define a dissimilarity matrix:**Select a suitable dissimilarity metric based on the nature of the data and the task at hand. Common dissimilarity metrics include Euclidean distance, Manhattan distance, Cosine similarity, Jaccard similarity, and many others. Each metric has its strengths and is appropriate for different types of data.\n",
        "\n",
        "###**Compute dissimilarities:**Use the chosen dissimilarity metric to calculate the dissimilarities between all pairs of data points in the DataFrame. This involves comparing each data point with every other data point and computing the dissimilarity score for each pair.\n",
        "\n",
        "###**Store the results in a dissimilarity matrix:**\n",
        "\n",
        "###The output of the computation will be a symmetric matrix, often referred to as the dissimilarity matrix. The matrix's size will be N x N, where N is thenumber of data points in the DataFrame. Each entry in the matrix represents the dissimilarity score between the corresponding pair of data points.\n",
        "\n",
        "###**Use the dissimilarity matrix for further analysis:**\n",
        "\n",
        "###The dissimilarity matrix is a valuable tool for clustering algorithms and other similarity-based tasks. It can be used as input for clustering algorithms such as hierarchical clustering, k-means, and DBSCAN, to group similar data points together based on their dissimilarities.\n",
        "\n",
        "###Converting a DataFrame to a dissimilarity matrix is an essential step in many data analysis andmachine learning tasks that involve measuring the similarity or dissimilarity between data"
      ],
      "metadata": {
        "id": "nLSVdiCDX2jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    \"swathi\": {\"Math\": 85, \"Science\": 90, \"English\": 78},\n",
        "    \"sarvani\": {\"Math\": 80, \"Science\": 85, \"English\": 82},\n",
        "    \"sneha\": {\"Math\": 92, \"Science\": 88, \"English\": 90},\n",
        "    \"teju\": {\"Math\": 88, \"Science\": 85, \"English\": 80},\n",
        "    \"junnu\": {\"Math\": 90, \"Science\": 95, \"English\": 88},\n",
        "}\n",
        "\n",
        "def calculate_distance(student1, student2):\n",
        "    subjects = list(data[student1].keys())\n",
        "    distance = 0\n",
        "    for subject in subjects:\n",
        "        distance += (data[student1][subject] - data[student2][subject]) ** 2\n",
        "    return np.sqrt(distance)\n",
        "\n",
        "def create_dissimilarity_matrix(students):\n",
        "    num_students = len(students)\n",
        "    dissimilarity_matrix = np.zeros((num_students, num_students))\n",
        "    for i in range(num_students):\n",
        "        for j in range(i, num_students):\n",
        "            distance = calculate_distance(students[i], students[j])\n",
        "            dissimilarity_matrix[i, j] = distance\n",
        "            dissimilarity_matrix[j, i] = distance\n",
        "    return dissimilarity_matrix\n",
        "\n",
        "students = [\"swathi\", \"sarvani\", \"sneha\", \"teju\", \"junnu\"]\n",
        "dissimilarity_matrix = create_dissimilarity_matrix(students)\n",
        "\n",
        "print(\"Dissimilarity Matrix:\")\n",
        "print()\n",
        "print(\" \", end=\" \")\n",
        "for j in students:\n",
        "    print(\" \" + j, end=\" \")\n",
        "print()\n",
        "for i, student in enumerate(students):\n",
        "    print(student, dissimilarity_matrix[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9g3M_99yBOy",
        "outputId": "b9aaa7f7-576d-43f4-b4ce-03428dcb2e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dissimilarity Matrix:\n",
            "\n",
            "   swathi  sarvani  sneha  teju  junnu \n",
            "swathi [ 0.          8.1240384  14.03566885  6.164414   12.24744871]\n",
            "sarvani [ 8.1240384   0.         14.73091986  8.24621125 15.3622915 ]\n",
            "sneha [14.03566885 14.73091986  0.         11.18033989  7.54983444]\n",
            "teju [ 6.164414    8.24621125 11.18033989  0.         12.9614814 ]\n",
            "junnu [12.24744871 15.3622915   7.54983444 12.9614814   0.        ]\n"
          ]
        }
      ]
    }
  ]
}